[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "qnn-cv-qsite",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport torchquantum as tq\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport torch.nn.functional as F\n\n\n# Load MNIST dataset\ntransform = transforms.Compose([transforms.ToTensor()])\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ntest_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n\n# Define data loaders\nbatch_size = 64\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n\n# Define a custom quantum layer with parameters\nclass QuantumLayer(nn.Module):\n    def __init__(self, input_size, output_size):\n        super(QuantumLayer, self).__init__()\n        # This is a placeholder; the actual quantum layer implementation may differ\n        self.fc = nn.Linear(input_size, output_size)\n        \n    \n\n    def forward(self, x):\n        # Apply some operations and return\n        return self.fc(x)\n\n# Define the quantum neural network model\nclass QuantumNeuralNetwork(nn.Module):\n    def __init__(self):\n        super(QuantumNeuralNetwork, self).__init__()\n        self.q_layer1 = QuantumLayer(28*28, 128)  # Define custom quantum layer\n        self.q_layer2 = QuantumLayer(128, 10)  # Define custom quantum layer\n\n    def forward(self, x):\n        x = self.q_layer1(x)\n        # Apply a quantum operation\n        # Note: Modify based on how torchquantum expects quantum operations to be applied\n        x = torch.relu(x)\n        x = self.q_layer2(x)\n        return x\n\n# Initialize the model, loss function, and optimizer\nmodel = QuantumNeuralNetwork()\ncriterion = nn.CrossEntropyLoss()\n# Initialize the model\nmodel = QuantumNeuralNetwork()\n\n# Define the optimizer with a specific learning rate\noptimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n\n# Train the model\nfor epoch in range(10):  # train for 10 epochs\n    for i, (images, labels) in enumerate(train_loader):\n        images = images.view(-1, 28*28)  # flatten the images\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        if i % 100 == 0:\n            print(f'Epoch {epoch+1}, Batch {i+1}, Loss: {loss.item()}')\n\n# Evaluate the model\nmodel.eval()\ntest_loss = 0\ncorrect = 0\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.view(-1, 28*28)\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        correct += (predicted == labels).sum().item()\n\naccuracy = correct / len(test_loader.dataset)\nprint(f'Test Loss: {test_loss / len(test_loader)}')\nprint(f'Test Accuracy: {accuracy:.2f}%')\n\nEpoch 1, Batch 1, Loss: 2.288099765777588\nEpoch 1, Batch 101, Loss: 0.3159481883049011\nEpoch 1, Batch 201, Loss: 0.3420783579349518\nEpoch 1, Batch 301, Loss: 0.1895936280488968\nEpoch 1, Batch 401, Loss: 0.35278838872909546\nEpoch 1, Batch 501, Loss: 0.2610619068145752\nEpoch 1, Batch 601, Loss: 0.13302923738956451\nEpoch 1, Batch 701, Loss: 0.19004277884960175\nEpoch 1, Batch 801, Loss: 0.16484005749225616\nEpoch 1, Batch 901, Loss: 0.19410748779773712\nEpoch 2, Batch 1, Loss: 0.1268109530210495\nEpoch 2, Batch 101, Loss: 0.30571448802948\nEpoch 2, Batch 201, Loss: 0.08373631536960602\nEpoch 2, Batch 301, Loss: 0.2199314534664154\nEpoch 2, Batch 401, Loss: 0.08536102622747421\nEpoch 2, Batch 501, Loss: 0.041027478873729706\nEpoch 2, Batch 601, Loss: 0.04469919949769974\nEpoch 2, Batch 701, Loss: 0.07798943668603897\nEpoch 2, Batch 801, Loss: 0.08364693075418472\nEpoch 2, Batch 901, Loss: 0.12893901765346527\nEpoch 3, Batch 1, Loss: 0.03497926890850067\nEpoch 3, Batch 101, Loss: 0.025604771450161934\nEpoch 3, Batch 201, Loss: 0.08356665819883347\nEpoch 3, Batch 301, Loss: 0.01599741168320179\nEpoch 3, Batch 401, Loss: 0.07620248198509216\nEpoch 3, Batch 501, Loss: 0.03759605437517166\nEpoch 3, Batch 601, Loss: 0.08331012725830078\nEpoch 3, Batch 701, Loss: 0.09592567384243011\nEpoch 3, Batch 801, Loss: 0.061507780104875565\nEpoch 3, Batch 901, Loss: 0.11098724603652954\nEpoch 4, Batch 1, Loss: 0.05818689614534378\nEpoch 4, Batch 101, Loss: 0.06918291747570038\nEpoch 4, Batch 201, Loss: 0.029523327946662903\nEpoch 4, Batch 301, Loss: 0.041717130690813065\nEpoch 4, Batch 401, Loss: 0.0976083055138588\nEpoch 4, Batch 501, Loss: 0.018132325261831284\nEpoch 4, Batch 601, Loss: 0.04666651040315628\nEpoch 4, Batch 701, Loss: 0.06500569730997086\nEpoch 4, Batch 801, Loss: 0.012028658762574196\nEpoch 4, Batch 901, Loss: 0.17851383984088898\nEpoch 5, Batch 1, Loss: 0.009146598167717457\nEpoch 5, Batch 101, Loss: 0.018540063872933388\nEpoch 5, Batch 201, Loss: 0.09087801724672318\nEpoch 5, Batch 301, Loss: 0.032599907368421555\nEpoch 5, Batch 401, Loss: 0.032275982201099396\nEpoch 5, Batch 501, Loss: 0.024265313521027565\nEpoch 5, Batch 601, Loss: 0.07824014127254486\nEpoch 5, Batch 701, Loss: 0.07055875658988953\nEpoch 5, Batch 801, Loss: 0.0442497618496418\nEpoch 5, Batch 901, Loss: 0.028142446652054787\nEpoch 6, Batch 1, Loss: 0.20632624626159668\nEpoch 6, Batch 101, Loss: 0.1183379665017128\nEpoch 6, Batch 201, Loss: 0.05767705664038658\nEpoch 6, Batch 301, Loss: 0.07270310074090958\nEpoch 6, Batch 401, Loss: 0.016020020470023155\nEpoch 6, Batch 501, Loss: 0.0883546769618988\nEpoch 6, Batch 601, Loss: 0.02136768400669098\nEpoch 6, Batch 701, Loss: 0.18510769307613373\nEpoch 6, Batch 801, Loss: 0.0713496059179306\nEpoch 6, Batch 901, Loss: 0.026228711009025574\nEpoch 7, Batch 1, Loss: 0.008920162916183472\nEpoch 7, Batch 101, Loss: 0.0276971235871315\nEpoch 7, Batch 201, Loss: 0.0019747153855860233\nEpoch 7, Batch 301, Loss: 0.03597347438335419\nEpoch 7, Batch 401, Loss: 0.026927120983600616\nEpoch 7, Batch 501, Loss: 0.05569939687848091\nEpoch 7, Batch 601, Loss: 0.04961194843053818\nEpoch 7, Batch 701, Loss: 0.011999131180346012\nEpoch 7, Batch 801, Loss: 0.019147302955389023\nEpoch 7, Batch 901, Loss: 0.04401218518614769\nEpoch 8, Batch 1, Loss: 0.030697252601385117\nEpoch 8, Batch 101, Loss: 0.007027680519968271\nEpoch 8, Batch 201, Loss: 0.010434912517666817\nEpoch 8, Batch 301, Loss: 0.12288504838943481\nEpoch 8, Batch 401, Loss: 0.039730630815029144\nEpoch 8, Batch 501, Loss: 0.058142099529504776\nEpoch 8, Batch 601, Loss: 0.0624447800219059\nEpoch 8, Batch 701, Loss: 0.0017424375982955098\nEpoch 8, Batch 801, Loss: 0.009535407647490501\nEpoch 8, Batch 901, Loss: 0.015877151861786842\nEpoch 9, Batch 1, Loss: 0.004276403225958347\nEpoch 9, Batch 101, Loss: 0.0539056658744812\nEpoch 9, Batch 201, Loss: 0.06793048977851868\nEpoch 9, Batch 301, Loss: 0.003677004249766469\nEpoch 9, Batch 401, Loss: 0.017131103202700615\nEpoch 9, Batch 501, Loss: 0.005584270693361759\nEpoch 9, Batch 601, Loss: 0.007832324132323265\nEpoch 9, Batch 701, Loss: 0.09199176728725433\nEpoch 9, Batch 801, Loss: 0.024681245908141136\nEpoch 9, Batch 901, Loss: 0.007175299804657698\nEpoch 10, Batch 1, Loss: 0.0027173408307135105\nEpoch 10, Batch 101, Loss: 0.00888118240982294\nEpoch 10, Batch 201, Loss: 0.007808873429894447\nEpoch 10, Batch 301, Loss: 0.005816053599119186\nEpoch 10, Batch 401, Loss: 0.005709032993763685\nEpoch 10, Batch 501, Loss: 0.05467400699853897\nEpoch 10, Batch 601, Loss: 0.010161708109080791\nEpoch 10, Batch 701, Loss: 0.024333704262971878\nEpoch 10, Batch 801, Loss: 0.08552942425012589\nEpoch 10, Batch 901, Loss: 0.027601368725299835\nTest Loss: 0.06988463613622585\nTest Accuracy: 0.98%\n\n\n\ndef plot_confusion_matrix(y_true, y_pred, classes):\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(10, 7))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n# Assuming you have y_true and y_pred\ny_true = []\ny_pred = []\nmodel.eval()\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.view(-1, 28*28)\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(predicted.cpu().numpy())\n\nplot_confusion_matrix(y_true, y_pred, classes=[str(i) for i in range(10)])\n\n\n\n\n\n\n\n\n\ndef plot_misclassified_examples(images, labels, predictions): #, save_path):\n    misclassified_indices = [i for i in range(len(labels)) if labels[i] != predictions[i]]\n    num_examples = min(len(misclassified_indices), 49)  # Display at most 49 examples for 7x7 grid\n    plt.figure(figsize=(14, 14))  # Adjust figure size for 7x7 grid\n    for i, index in enumerate(misclassified_indices[:num_examples]):\n        plt.subplot(7, 7, i+1)  # 7x7 grid\n        plt.imshow(images[index].reshape(28, 28), cmap='gray')\n        plt.title(f'T: {labels[index]}, P: {predictions[index]}', fontsize=8)\n        plt.axis('off')\n    plt.tight_layout()\n    #plt.savefig(save_path, dpi=240)  # Save the plot with 240 DPI\n    plt.close()\n\n# Collect misclassified examples\nmisclassified_images = []\nmisclassified_labels = []\nmisclassified_predictions = []\nfor images, labels in test_loader:\n    images = images.view(-1, 28*28)\n    outputs = model(images)\n    _, predicted = torch.max(outputs, 1)\n    for i in range(len(labels)):\n        if labels[i] != predicted[i]:\n            misclassified_images.append(images[i].cpu().numpy())\n            misclassified_labels.append(labels[i].cpu().numpy())\n            misclassified_predictions.append(predicted[i].cpu().numpy())\n\n# Define the path where the plot will be saved\n#save_path = './images/misclassified_examples.png'\nplot_misclassified_examples(misclassified_images, misclassified_labels, misclassified_predictions)#, save_path)\n\n\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(28*28, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n# Train and evaluate a classical model\nsimple_nn = SimpleNN()\noptimizer = torch.optim.Adam(simple_nn.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()\n\n# Training loop for classical model (similar to QNN training loop)\n\n# Evaluation loop for classical model\nsimple_nn.eval()\ntest_loss = 0\ncorrect = 0\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.view(-1, 28*28)\n        outputs = simple_nn(images)\n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        correct += (predicted == labels).sum().item()\n\naccuracy = correct / len(test_loader.dataset)\nprint(f'Classical Model Test Loss: {test_loss / len(test_loader)}')\nprint(f'Classical Model Test Accuracy: {accuracy:.2f}%')\n\nClassical Model Test Loss: 2.298474659585649\nClassical Model Test Accuracy: 0.10%\n\n\n\ndef plot_correctly_classified_examples(images, labels, predictions): #, save_path):\n    correctly_classified_indices = [i for i in range(len(labels)) if labels[i] == predictions[i]]\n    num_examples = min(len(correctly_classified_indices), 49)  # Display at most 49 examples for 7x7 grid\n    plt.figure(figsize=(14, 14))  # Adjust figure size for 7x7 grid\n    for i, index in enumerate(correctly_classified_indices[:num_examples]):\n        plt.subplot(7, 7, i+1)  # 7x7 grid\n        plt.imshow(images[index].reshape(28, 28), cmap='gray')\n        plt.title(f'T: {labels[index]}, P: {predictions[index]}', fontsize=8)\n        plt.axis('off')\n    plt.tight_layout()\n    #plt.savefig(save_path, dpi=240)  # Save the plot with 240 DPI\n    plt.close()\n\n# Collect correctly classified examples\ncorrect_images = []\ncorrect_labels = []\ncorrect_predictions = []\nfor images, labels in test_loader:\n    images = images.view(-1, 28*28)\n    outputs = model(images)\n    _, predicted = torch.max(outputs, 1)\n    for i in range(len(labels)):\n        if labels[i] == predicted[i]:  # Only store correctly classified examples\n            correct_images.append(images[i].cpu().numpy())\n            correct_labels.append(labels[i].cpu().numpy())\n            correct_predictions.append(predicted[i].cpu().numpy())\n\n# Define the path where the plot will be saved\n#save_path = './images/correctly_classified_examples.png'\nplot_correctly_classified_examples(correct_images, correct_labels, correct_predictions)#, save_path)\n\n\n# Initialize counters for correct and total predictions\ncorrect = 0\ntotal = 0\n\n# Iterate through test dataset to calculate correct predictions\nfor images, labels in test_loader:\n    images = images.view(-1, 28*28)\n    outputs = model(images)\n    _, predicted = torch.max(outputs, 1)\n    \n    # Increment total count\n    total += labels.size(0)\n    \n    # Increment correct count if prediction matches the label\n    correct += (predicted == labels).sum().item()\n\n# Calculate and print the ratio\nratio = correct / total\nprint(f'Correctly Classified: {correct} out of {total}')\nprint(f'Ratio of correctly classified examples: {ratio:.4f}')\n\nCorrectly Classified: 9799 out of 10000\nRatio of correctly classified examples: 0.9799"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]